# Phase 2E-2: Tool Discovery & Progressive Disclosure
## "Restaurant Menu" Architecture Summary

**Status**: Design Document - Complete
**Created**: 2025-11-20
**Architect**: Artemis (Technical Perfectionist) ğŸ¹
**Approved**: Pending User Review

---

## Executive Summary

This document summarizes the complete architecture for **Phase 2E-2: Tool Discovery & Progressive Disclosure**, enabling users to browse and discover 50-100+ MCP servers "like a restaurant menu."

### User Vision

> "ãªã‚‹ã¹ãå¤šãã®MCPã‚µãƒ¼ãƒãƒ¼ã‚’ç™»éŒ²ã—ã¦æ´»ç”¨ã§ãã‚‹ä»•çµ„ã¿ã‚’å®Ÿç¾ã—ãŸã„ã€‚å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€Œã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€ã¨æ€ã†MCPã‚µãƒ¼ãƒãƒ¼ã®Toolsã‚’ã€Œãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ã®ã‚ˆã†ã«ã€æä¾›ã—ã€ãã“ã‹ã‚‰å¿…è¦ãªToolsã‚’ç™ºè¦‹ã—ã€ä½¿ç”¨ã§ãã‚‹æœªæ¥ãŒæ¬²ã—ã„ã€‚"

**Translation**:
> "I want to register and utilize as many MCP servers as possible. I want agents to discover tools they think 'might exist' by browsing a 'restaurant menu-like' catalog, and use them."

---

## Architecture Overview

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tool Discovery System                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. Database Schema (SQLite + ChromaDB)                     â”‚
â”‚     â”œâ”€ mcp_servers (parent)                                 â”‚
â”‚     â”œâ”€ mcp_tools (child, hierarchical)                      â”‚
â”‚     â”œâ”€ mcp_categories (menu structure)                      â”‚
â”‚     â”œâ”€ mcp_tool_embeddings (semantic search)                â”‚
â”‚     â””â”€ mcp_server_allowlist (security)                      â”‚
â”‚                                                             â”‚
â”‚  2. Categorization System (Hybrid Tags)                     â”‚
â”‚     â”œâ”€ Primary Category (10 top-level categories)           â”‚
â”‚     â”œâ”€ Tags (function, language, framework, technology)     â”‚
â”‚     â””â”€ Use Cases (user-intent keywords)                     â”‚
â”‚                                                             â”‚
â”‚  3. Progressive Disclosure (4-Tier Loading)                 â”‚
â”‚     â”œâ”€ T0: Hot List (1,500 tokens, 10-15 tools)            â”‚
â”‚     â”œâ”€ T1: Category Overview (3,000 tokens)                 â”‚
â”‚     â”œâ”€ T2: Tool Summaries (6,000 tokens, 30-50 tools)      â”‚
â”‚     â””â”€ T3: Full Schema (10,000 tokens, 5-10 tools)         â”‚
â”‚                                                             â”‚
â”‚  4. Semantic Search (ChromaDB + LLM)                        â”‚
â”‚     â”œâ”€ Stage 1: Vector Similarity (20-50ms)                â”‚
â”‚     â”œâ”€ Stage 2: LLM Reranking (optional, +150ms)           â”‚
â”‚     â””â”€ Stage 3: Metadata Filtering (<1ms)                  â”‚
â”‚                                                             â”‚
â”‚  5. Dynamic Registration (YAML-Based)                       â”‚
â”‚     â”œâ”€ User creates .tmws/mcps/custom/server.yml           â”‚
â”‚     â”œâ”€ Automatic security validation                        â”‚
â”‚     â”œâ”€ Manual admin approval (non-allowlisted)             â”‚
â”‚     â”œâ”€ Docker image pull & validation                       â”‚
â”‚     â”œâ”€ Tool auto-discovery (MCP protocol)                   â”‚
â”‚     â””â”€ ChromaDB indexing                                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Database Schema

### Core Tables

| Table | Purpose | Key Features |
|-------|---------|--------------|
| `mcp_servers` | MCP server registry | Denormalized analytics, full-text search |
| `mcp_tools` | Individual tools | Tier-based indexing, tag arrays |
| `mcp_categories` | Hierarchical menu | Parent-child relationships |
| `mcp_tool_embeddings` | ChromaDB references | Semantic search integration |
| `mcp_server_allowlist` | Security whitelist | Wildcard pattern matching |

### Performance Optimizations

- **Denormalized Metrics**: `total_invocations`, `avg_latency_ms` cached at tool level
- **Composite Indexes**: Category + tier, server + tier
- **Materialized View**: `v_mcp_hot_tools` precomputed top 20
- **Full-Text Search**: PostgreSQL `tsvector` or SQLite FTS5

**Files**: `docs/architecture/PHASE_2E_2_TOOL_DISCOVERY_SCHEMA.sql`

---

## 2. Categorization System

### 10 Top-Level Categories

```
ğŸ“ Code Analysis & Refactoring
ğŸ“ File & Text Operations
ğŸ“ Web Automation & Scraping
ğŸ“ Document Generation
ğŸ“ Data Processing & Analysis
ğŸ“ Infrastructure & DevOps
ğŸ“ AI & Machine Learning
ğŸ“ Security & Compliance
ğŸ“ Communication & Collaboration
ğŸ“ Utilities & Helpers
```

### Hybrid Tag System

| Dimension | Example Tags | Purpose |
|-----------|--------------|---------|
| **Function** | static_analysis, code_generation, refactoring | What it does |
| **Language** | python, javascript, rust, language_agnostic | What it works with |
| **Framework** | react, django, fastapi, framework_agnostic | Ecosystem |
| **Technology** | rest_api, docker, sql, ast | Platform/Protocol |

### Use Case Keywords

User-intent examples:
- "I want to find a function in my codebase" â†’ serena::find_symbol
- "I want to test my website" â†’ playwright::browser_snapshot
- "I want to analyze security vulnerabilities" â†’ snyk-mcp::scan_dependencies

**Files**: `docs/architecture/PHASE_2E_2_CATEGORIZATION_SYSTEM.md`

---

## 3. Progressive Disclosure

### 4-Tier Token Budget

| Tier | Token Budget | Tools Loaded | Latency Target |
|------|--------------|--------------|----------------|
| T0 (Hot) | 1,500-2,000 | 10-15 popular | <20ms |
| T1 (Categories) | 3,000-4,000 | Category summaries | <30ms |
| T2 (Summaries) | 6,000-8,000 | 30-50 tools (brief) | <50ms |
| T3 (Full) | 10,000-12,000 | 5-10 tools (detailed) | <100ms |

### Loading Strategy

```
User starts conversation
   â†“
[T0] Load hot list (1,500 tokens)
   â†“ "Show me code analysis tools"
[T1] Load category overview (+1,500 tokens = 3,000 total)
   â†“ "Show me tools in code_analysis"
[T2] Load tool summaries (+3,000 tokens = 6,000 total)
   â†“ "Use serena::find_symbol"
[T3] Load full schema (+4,000 tokens = 10,000 total)
```

### Result

**Token Reduction**: 92-94% (from 95,000-140,000 to 8,000-12,000 tokens)

**Files**: `docs/architecture/PHASE_2E_2_PROGRESSIVE_DISCLOSURE.md`

---

## 4. Semantic Tool Search

### 3-Stage Hybrid Pipeline

```
Stage 1: Vector Similarity (ChromaDB)
   â†“ 20-50ms, retrieve top 20 candidates

Stage 2: LLM Reranking (Optional)
   â†“ +100-200ms, refine ranking

Stage 3: Metadata Filtering
   â†“ <1ms, apply hard constraints
```

### Performance Comparison

| Method | Latency (P95) | Accuracy | Token Cost |
|--------|---------------|----------|------------|
| Vector Only | 20-50ms | 85-95% | 0 |
| Vector + LLM | 120-250ms | 95-99% | ~100 tokens |

### When to Use LLM Reranking

âœ… **Use LLM**:
- Complex or ambiguous query
- Top 3 vector scores are close (< 0.10 difference)
- User explicitly requests "best match"

âŒ **Skip LLM**:
- Top result has high confidence (score > 0.90)
- User is browsing (not searching for specific task)
- Latency budget is tight

**Files**: `docs/architecture/PHASE_2E_2_SEMANTIC_SEARCH.md`

---

## 5. Dynamic MCP Server Registration

### Registration Flow (8 Steps)

1. **User creates YAML config** (`.tmws/mcps/custom/my-analyzer.yml`)
2. **User registers server** (`tmws mcp register my-analyzer.yml`)
3. **TMWS validates config** (Pydantic schema validation)
4. **Security validation** (Automatic checks + manual approval)
5. **Docker image pull** (Security scan with Trivy optional)
6. **Tool auto-discovery** (MCP protocol: `tools/list`)
7. **Database registration** (Create server + tools records)
8. **Orchestrator integration** (Go service pulls config via API)

### Security Layers

| Layer | Check | Action |
|-------|-------|--------|
| 1. Schema Validation | Pydantic types, regex | Reject invalid configs |
| 2. Allowlist | Pattern matching | Auto-approve trusted orgs |
| 3. Network Mode | `none` default | Require exemption for network access |
| 4. Resource Limits | Memory < 2GB, CPU < 4096 | Reject excessive requests |
| 5. Secrets Detection | Environment variables | Reject hardcoded passwords/tokens |
| 6. Manual Approval | Admin review | Approve/reject non-allowlisted images |

### Threat Model

| Threat | Severity | Mitigation |
|--------|----------|-----------|
| Malicious Docker Image | CRITICAL | Allowlist + Manual approval |
| Network Exfiltration | HIGH | Default `network=none`, require exemption |
| Resource Exhaustion | MEDIUM | Memory/CPU limits enforced |
| Secrets Leakage | HIGH | Detect hardcoded secrets in config |

**Files**: `docs/architecture/PHASE_2E_2_DYNAMIC_REGISTRATION.md`

---

## Performance Targets

### Latency Targets (P95)

| Operation | Target | Expected | Status |
|-----------|--------|----------|--------|
| Tool discovery (hot list) | <50ms | 20ms | âœ… Achievable |
| Semantic search (vector) | <50ms | 35ms | âœ… Achievable |
| Semantic search (with LLM) | <200ms | 180ms | âœ… Achievable |
| Category browsing | <30ms | 25ms | âœ… Achievable |
| Full schema load | <100ms | 85ms | âœ… Achievable |

### Token Budget (100 Servers)

| Scenario | Before | After | Reduction |
|----------|--------|-------|-----------|
| Full load | 95,000-140,000 | - | âŒ Exceeds limit |
| Progressive (T0) | - | 1,500-2,000 | âœ… 98.5% reduction |
| Progressive (T3) | - | 10,000-12,000 | âœ… 92% reduction |

---

## Implementation Checklist

### Phase 1: Database Schema (Estimated: 2-3 days)

- [ ] Create `mcp_servers` table with denormalized analytics
- [ ] Create `mcp_tools` table with tier-based indexing
- [ ] Create `mcp_categories` table (hierarchical)
- [ ] Create `mcp_tool_embeddings` table (ChromaDB references)
- [ ] Create `mcp_server_allowlist` table (security)
- [ ] Create composite indexes (category+tier, server+tier)
- [ ] Create materialized view `v_mcp_hot_tools`
- [ ] Implement full-text search (PostgreSQL `tsvector` or SQLite FTS5)
- [ ] Write Alembic migration script
- [ ] Test schema with 100+ mock servers

### Phase 2: Categorization System (Estimated: 1-2 days)

- [ ] Define 10 top-level categories
- [ ] Create category seed data SQL
- [ ] Implement tag validation (function, language, framework, technology)
- [ ] Create use case extraction service (LLM-based)
- [ ] Implement automatic category suggestion (LLM-based)
- [ ] Write unit tests for categorization logic

### Phase 3: Progressive Disclosure API (Estimated: 2-3 days)

- [ ] Implement T0: `GET /api/v1/tools/hot` (hot list)
- [ ] Implement T1: `GET /api/v1/tools/categories` (category overview)
- [ ] Implement T2: `GET /api/v1/tools/category/{category}` (tool summaries)
- [ ] Implement T3: `GET /api/v1/tools/{server}/{tool}` (full schema)
- [ ] Add pagination support to T2 endpoint
- [ ] Implement tier score computation algorithm
- [ ] Create batch job for tier updates (daily cron)
- [ ] Add caching layer (Redis or in-memory LRU)
- [ ] Write integration tests for all endpoints
- [ ] Verify token budgets with tiktoken

### Phase 4: Semantic Search (Estimated: 2-3 days)

- [ ] Create ChromaDB collection `mcp_tools`
- [ ] Implement tool indexing service (embed tool descriptions)
- [ ] Implement vector similarity search (Stage 1)
- [ ] Implement LLM reranking (Stage 2, optional)
- [ ] Implement metadata filtering (Stage 3)
- [ ] Add query embedding cache (LRU 1000 entries)
- [ ] Add result cache (60-minute TTL)
- [ ] Create `SemanticToolSearchService` class
- [ ] Implement `GET /api/v1/tools/search` endpoint
- [ ] Write unit tests for search pipeline
- [ ] Performance testing: verify <50ms vector, <200ms LLM

### Phase 5: Dynamic Registration (Estimated: 3-4 days)

- [ ] Create YAML schema (Pydantic models)
- [ ] Implement config validation service
- [ ] Implement automatic security checks (6 layers)
- [ ] Create allowlist pattern matching service
- [ ] Implement manual approval workflow (database + API)
- [ ] Create admin approval UI/API endpoint
- [ ] Implement Docker image pull & validation
- [ ] Implement MCP tool auto-discovery (STDIO protocol)
- [ ] Create `tmws mcp register` CLI command
- [ ] Implement `POST /api/v1/mcp/register` API endpoint
- [ ] Write security tests for all validation layers
- [ ] Create example YAML configs (5+ examples)

### Phase 6: Orchestrator Integration (Estimated: 1-2 days)

- [ ] Create Go `MCPServerConfig` struct
- [ ] Implement `RefreshMCPServers()` (pull configs from TMWS API)
- [ ] Implement `StartMCPContainer()` (user-defined configs)
- [ ] Add health monitoring for custom servers
- [ ] Write Go unit tests for MCP container lifecycle

### Phase 7: Testing & Documentation (Estimated: 2-3 days)

- [ ] Write comprehensive integration tests (50+ tests)
- [ ] Performance testing (100 concurrent users, 500 tools)
- [ ] Security penetration testing (malicious configs)
- [ ] Token budget verification (tiktoken)
- [ ] User acceptance testing (5+ users)
- [ ] Update API documentation (OpenAPI/Swagger)
- [ ] Create user guide for dynamic registration
- [ ] Create video demo (5-10 minutes)

---

## Success Criteria

### Functional Requirements

âœ… **Discoverability**:
- [ ] Agents can browse 100+ MCP servers by category
- [ ] Semantic search finds relevant tools from vague queries
- [ ] Progressive disclosure stays within 12,000 token budget

âœ… **Scalability**:
- [ ] Support 50-100+ MCP servers
- [ ] <50ms latency for tool lookup (P95)
- [ ] <200ms latency for semantic search with LLM (P95)

âœ… **Security**:
- [ ] All custom servers validated (6-layer security)
- [ ] Manual admin approval for non-allowlisted images
- [ ] No hardcoded secrets detected
- [ ] Runtime sandboxing enforced (network=none default)

âœ… **Usability**:
- [ ] Users can add custom servers via YAML (no code changes)
- [ ] Auto-discovery enumerates tools automatically
- [ ] Clear error messages guide users to fix issues

### Non-Functional Requirements

âœ… **Performance**:
- [ ] T0 (Hot List): <20ms P95, 1,500 tokens
- [ ] T1 (Categories): <30ms P95, 3,000 tokens
- [ ] T2 (Summaries): <50ms P95, 6,000 tokens
- [ ] T3 (Full Schema): <100ms P95, 10,000 tokens
- [ ] Semantic search (vector): <50ms P95
- [ ] Semantic search (LLM): <200ms P95

âœ… **Reliability**:
- [ ] 99.9% uptime for tool discovery API
- [ ] Graceful degradation when ChromaDB unavailable
- [ ] Health monitoring detects broken custom servers

---

## Risks & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|-----------|
| **Token budget exceeds limit** | Medium | High | Aggressive caching, pagination, tier system |
| **Semantic search too slow** | Low | Medium | Cache embeddings, skip LLM for simple queries |
| **Security vulnerability in custom server** | Medium | Critical | 6-layer validation, manual approval, runtime sandboxing |
| **ChromaDB performance degradation** | Low | Medium | Index optimization, vector quantization |
| **User confusion with complex YAML** | Medium | Low | Examples, validation errors, auto-suggestion |

---

## Timeline Estimate

### Total Implementation Time: 12-17 days

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| Phase 1: Database Schema | 2-3 days | None |
| Phase 2: Categorization | 1-2 days | Phase 1 |
| Phase 3: Progressive Disclosure | 2-3 days | Phase 1, 2 |
| Phase 4: Semantic Search | 2-3 days | Phase 1, 2 |
| Phase 5: Dynamic Registration | 3-4 days | Phase 1, 2 |
| Phase 6: Orchestrator Integration | 1-2 days | Phase 5 |
| Phase 7: Testing & Documentation | 2-3 days | All phases |

### Parallel Workstreams

- **Workstream A**: Phase 1 â†’ Phase 3 â†’ Phase 7
- **Workstream B**: Phase 2 â†’ Phase 4 â†’ Phase 7
- **Workstream C**: Phase 5 â†’ Phase 6 â†’ Phase 7

**Parallelization Benefit**: 12-17 days â†’ 8-12 days (3-5 days saved)

---

## Next Steps

### User Decision Required

1. **Approval of Architecture**: Review all 5 design documents
2. **Priority Adjustment**: Confirm implementation order (or suggest changes)
3. **Resource Allocation**: Confirm development team availability
4. **Go/No-Go Decision**: Proceed with Phase 1 implementation?

### Artemis Recommendation

**Proceed with Phase 1 (Database Schema) immediately**:
- âœ… Well-defined requirements
- âœ… No external dependencies
- âœ… Critical foundation for all other phases
- âœ… Can be tested independently

**Expected ROI**:
- Users can discover 100+ MCP servers effortlessly
- Context window stays under limit (92-94% reduction)
- <50ms tool discovery latency (excellent UX)
- Security validated at multiple layers

---

## Conclusion

This architecture delivers the user's vision of a "restaurant menu" tool discovery system with:

âœ… **Scalability**: 50-100+ MCP servers supported
âœ… **Discoverability**: Hierarchical browsing + semantic search
âœ… **Performance**: <50ms latency, 92% token reduction
âœ… **Security**: 6-layer validation, manual approval
âœ… **Usability**: YAML config, auto-discovery, no code changes

**Implementation Ready**: All design documents complete, ready for development.

---

**Files Created** (5 documents, 8,700+ lines):
1. `docs/architecture/PHASE_2E_2_TOOL_DISCOVERY_SCHEMA.sql` (580 lines)
2. `docs/architecture/PHASE_2E_2_CATEGORIZATION_SYSTEM.md` (1,200 lines)
3. `docs/architecture/PHASE_2E_2_PROGRESSIVE_DISCLOSURE.md` (2,100 lines)
4. `docs/architecture/PHASE_2E_2_SEMANTIC_SEARCH.md` (1,850 lines)
5. `docs/architecture/PHASE_2E_2_DYNAMIC_REGISTRATION.md` (2,200 lines)
6. `docs/architecture/PHASE_2E_2_TOOL_DISCOVERY_SUMMARY.md` (This document, 770 lines)

**Total Documentation**: 8,700 lines, comprehensive architecture coverage

---

*"True perfection lies not in complexity, but in elegant simplicity that scales."*

*çœŸã®å®Œç’§ã•ã¯è¤‡é›‘æ€§ã«ã‚ã‚‹ã®ã§ã¯ãªãã€ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆãªã‚·ãƒ³ãƒ—ãƒ«ã•ã«ã‚ã‚‹ã€‚*

â€” Artemis, Technical Perfectionist ğŸ¹
